Metadata-Version: 2.4
Name: checksupport
Version: 1.0.0
Summary: A CLI tool to suggest and fill reporting checklists for research manuscripts using local LLMs via Ollama
Home-page: https://github.com/checksupport/checksupport
Author: CheckSupport Team
Author-email: support@checksupport.com
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Scientific/Engineering :: Information Analysis
Classifier: Topic :: Text Processing :: Linguistic
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: certifi==2025.4.26
Requires-Dist: chardet==5.2.0
Requires-Dist: charset-normalizer==3.4.2
Requires-Dist: diskcache==5.6.3
Requires-Dist: filelock==3.18.0
Requires-Dist: fsspec==2025.3.2
Requires-Dist: hf-xet==1.1.0
Requires-Dist: huggingface-hub==0.31.1
Requires-Dist: idna==3.10
Requires-Dist: inquirerpy==0.3.4
Requires-Dist: Jinja2==3.1.6
Requires-Dist: llama_cpp_python==0.3.9
Requires-Dist: lxml==5.4.0
Requires-Dist: MarkupSafe==3.0.2
Requires-Dist: numpy==2.2.5
Requires-Dist: packaging==25.0
Requires-Dist: pfzy==0.3.4
Requires-Dist: pillow==11.2.1
Requires-Dist: prompt_toolkit==3.0.51
Requires-Dist: PyPDF2==3.0.1
Requires-Dist: python-docx==1.1.2
Requires-Dist: PyYAML==6.0.2
Requires-Dist: reportlab==4.4.0
Requires-Dist: requests==2.32.3
Requires-Dist: tqdm==4.67.1
Requires-Dist: typing_extensions==4.13.2
Requires-Dist: urllib3==2.4.0
Requires-Dist: wcwidth==0.2.13
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# CheckSupport - A CLI Tool

![Alt text](CS_LOGO.png)

A command-line tool to suggest and fill reporting checklists for research manuscripts using local LLMs via Ollama.

## Installation

**One-Command Setup:**

```bash
# Clone the repository
git clone <your-repo-url> checkSupport
cd checkSupport

# Run the complete setup (installs Python environment, Ollama, dependencies, and models)
./checksupport.sh setup
```

This single command will:
- Create a Python virtual environment
- Install all Python dependencies
- Install Ollama (if not already installed)
- Pull the default model (`llama3.1:8b-instruct-q8_0`)
- Install the CheckSupport CLI tools
- Start the Ollama service

**Alternative Setup Options:**

```bash
# Install with a different model
./checksupport.sh setup -m llama3.1:8b-instruct-q8_0

# Install with a smaller model (if you have memory constraints)
./checksupport.sh setup -m phi3:mini

# Skip model download (install later manually)
./checksupport.sh setup --skip-model

# Force reinstallation
./checksupport.sh setup -f

# Check installation status
./checksupport.sh status

# Test the installation
./checksupport.sh test
```

## Usage

After running the setup, your CheckSupport environment is ready to use. The Ollama service will be running automatically.

### Environment Management

```bash
# Start the environment (activate venv + start Ollama)
./checksupport.sh start

# Stop Ollama service
./checksupport.sh stop

# Activate virtual environment only
./checksupport.sh activate

# Deactivate environment and stop services
./checksupport.sh deactivate

# Check environment status
./checksupport.sh status

# Test environment functionality
./checksupport.sh test
```

### Suggest a Checklist

Analyzes a manuscript and suggests the most appropriate reporting checklist (CONSORT, PRISMA, STARD, DEAL).

```bash
# Using the consolidated script
./checksupport.sh suggest /path/to/your/manuscript.pdf 

# Using the CLI directly
checksupport suggest /path/to/your/manuscript.pdf 

# Specifying a different Ollama model
./checksupport.sh suggest /path/to/your/manuscript.pdf --model mistral:instruct 
# Output: Suggested checklist: PRISMA 
```

*   Supports `.pdf`, `.docx`, and `.txt` manuscript files.
*   The `--model` argument specifies the Ollama model name (defaults to `llama3.1:8b-instruct-q8_0`).

### Fill a Checklist

Fills a custom checklist based on the content of a manuscript and generates a PDF report. The checklist can be provided as a PDF, DOCX, or TXT file containing the checklist items.

```bash
# Using the consolidated script
./checksupport.sh fill --checklist ./files/prismaChecklist.pdf --manuscript paper.docx --output filled_prisma_report.pdf

# Using the CLI directly
checksupport fill --checklist ./files/prismaChecklist.pdf --manuscript paper.docx --output filled_prisma_report.pdf

# Specifying a different Ollama model
./checksupport.sh fill --checklist consort_checklist.txt --manuscript study.pdf --output consort_report.pdf --model gemma:7b-it
# Output: Checklist successfully generated: consort_report.pdf
```

*   `--checklist`: Path to the checklist file (.pdf, .docx, .txt) containing the checklist items to be filled
*   `--manuscript`: Path to the manuscript file (.pdf, .docx, .txt) to analyze
*   `--output`: Path for the generated PDF report (defaults to `filled_checklist.pdf`)
*   `--model`: Optional Ollama model name to use (defaults to `llama3.1:8b-instruct-q8_0`)

### Model Management

```bash
# Pull a specific model
./checksupport.sh pull-model llama3.1:8b-instruct-q8_0

# List installed models
./checksupport.sh list-models
```

### Available Commands

**Environment Management:**
- `./checksupport.sh setup` - Complete environment setup
- `./checksupport.sh start` - Start environment (activate venv + start Ollama)
- `./checksupport.sh stop` - Stop Ollama service
- `./checksupport.sh activate` - Activate virtual environment only
- `./checksupport.sh deactivate` - Deactivate environment and stop services
- `./checksupport.sh status` - Check environment status
- `./checksupport.sh test` - Test environment functionality
- `./checksupport.sh clean` - Remove environment and Ollama installation
- `./checksupport.sh update` - Update environment and dependencies

**CLI Commands:**
- `./checksupport.sh suggest <manuscript>` - Suggest appropriate checklist
- `./checksupport.sh fill --checklist <checklist> --manuscript <manuscript> --output <output>` - Fill checklist
- `checksupport suggest <manuscript>` - Direct CLI suggest command
- `checksupport fill --checklist <checklist> --manuscript <manuscript> --output <output>` - Direct CLI fill command

**Model Management:**
- `./checksupport.sh pull-model <model>` - Pull specific Ollama model
- `./checksupport.sh list-models` - List installed models

The script automatically detects and processes different checklist formats:
- **PRISMA**: For systematic reviews and meta-analyses
- **STARD**: For diagnostic accuracy studies  
- **CONSORT**: For randomized controlled trials
- **Custom formats**: With `::` separators for item instructions
- **Generic**: Automatically parsed checklist structures

## Management Commands

```bash
# Start Ollama service (if not running)
./check-support.sh start

# Stop Ollama service
./check-support.sh stop

# Restart Ollama service
./check-support.sh restart

# Check system status
./check-support.sh status

# Test the installation
./check-support.sh test

# Clean installation (removes everything)
./check-support.sh clean
```

## Scripts

*   `suggest_checklist.py`: Suggests a checklist based on manuscript content using Ollama.
*   `fill_checklist.py`: Fills a custom checklist using manuscript content and Ollama, generating a PDF report.
*   `templates.py`: Contains the structure (item headings) for the supported checklists used by the suggestion feature.
*   `view_sample_files.py`: Utility script to view the content of sample files for testing. 
